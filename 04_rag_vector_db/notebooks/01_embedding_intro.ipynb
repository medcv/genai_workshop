{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a5ab2f-d044-4956-b75b-7408d9c3e323",
   "metadata": {},
   "source": [
    "# Introduction to Amazon Bedrock and the concept of embeddings\n",
    "\n",
    "> *PLEASE NOTE: This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio. Also, you should have provisioned access in your AWS account for the required Bedrock models as described [here](https://catalog.us-east-1.prod.workshops.aws/event/dashboard/en-US/workshop/20-introduction/21-bedrock).*\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will set up the [`boto3` Python SDK](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) to work with [Amazon Bedrock](https://aws.amazon.com/bedrock/) Foundation Models as well as install extra dependencies needed for this workshop. Specifically, we will be using the following libraries throughout the workshop...\n",
    "\n",
    "* [LangChain](https://python.langchain.com/docs/get_started/introduction) for large language model (LLM) utilities\n",
    "* [FAISS](https://github.com/facebookresearch/faiss) for vector similarity searching\n",
    "* [Streamlit](https://streamlit.io/) for user interface (UI) building\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d5409",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673f25fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating base environment\n",
      "Base environment validated successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #4cc9f0; text-decoration-color: #4cc9f0; font-weight: bold\">Validating lab environment from requirements.txt</span> ✨\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;76;201;240mValidating lab environment from requirements.txt\u001b[0m ✨\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #e85d04; text-decoration-color: #e85d04; font-weight: bold; text-decoration: underline\">ENVIRONMENT STATUS</span>\n",
       "✅ <span style=\"color: #008000; text-decoration-color: #008000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">langchain</span><span style=\"color: #008000; text-decoration-color: #008000\">==</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.1</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">14</span><span style=\"color: #008000; text-decoration-color: #008000\"> is installed</span>\n",
       "✅ <span style=\"color: #008000; text-decoration-color: #008000\"> langchain-aws is installed</span>\n",
       "✅ <span style=\"color: #008000; text-decoration-color: #008000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">xmltodict</span><span style=\"color: #008000; text-decoration-color: #008000\">==</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.13</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> is installed</span>\n",
       "✅ <span style=\"color: #008000; text-decoration-color: #008000\"> pypdf&gt;=</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3.8</span><span style=\"color: #008000; text-decoration-color: #008000\">,</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">&lt;</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000\"> is installed</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">❌ </span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">pillow</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">==</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">9.4</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">.</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">0</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\"> is not installed</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">❌ </span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">streamlit</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">==</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">1.27</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">.</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">0</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\"> is not installed</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">❌ </span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">streamlit-</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">chat</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">==</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">0.1</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">.</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">1</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\"> is not installed</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">❌ </span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">faiss-cpu</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">&gt;</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">=</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">1.7</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">,&lt;</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">2</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\"> is not installed</span>\n",
       "❌ <span style=\"color: #ef233c; text-decoration-color: #ef233c\">unstructured</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">==</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">0.10</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">.</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">16</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\"> is not installed</span>\n",
       "❌ <span style=\"color: #ef233c; text-decoration-color: #ef233c\">sqlalchemy</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">==</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">2.0</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">.</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">21</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\"> is not installed</span>\n",
       "❌ <span style=\"color: #ef233c; text-decoration-color: #ef233c\">opensearch-</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">py</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">==</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">2.3</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\">.</span><span style=\"color: #ef233c; text-decoration-color: #ef233c; font-weight: bold\">1</span><span style=\"color: #ef233c; text-decoration-color: #ef233c\"> is not installed</span>\n",
       "❌ <span style=\"color: #ef233c; text-decoration-color: #ef233c\">tiktoken is not installed</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;4;38;2;232;93;4mENVIRONMENT STATUS\u001b[0m\n",
       "✅ \u001b[32m \u001b[0m\u001b[32mlangchain\u001b[0m\u001b[32m==\u001b[0m\u001b[1;32m0.1\u001b[0m\u001b[32m.\u001b[0m\u001b[1;32m14\u001b[0m\u001b[32m is installed\u001b[0m\n",
       "✅ \u001b[32m langchain-aws is installed\u001b[0m\n",
       "✅ \u001b[32m \u001b[0m\u001b[32mxmltodict\u001b[0m\u001b[32m==\u001b[0m\u001b[1;32m0.13\u001b[0m\u001b[32m.\u001b[0m\u001b[1;32m0\u001b[0m\u001b[32m is installed\u001b[0m\n",
       "✅ \u001b[32m pypdf>=\u001b[0m\u001b[1;32m3.8\u001b[0m\u001b[32m,\u001b[0m\u001b[1;32m<\u001b[0m\u001b[1;32m4\u001b[0m\u001b[32m is installed\u001b[0m\n",
       "\u001b[39m❌ \u001b[0m\u001b[38;2;239;35;60mpillow\u001b[0m\u001b[38;2;239;35;60m==\u001b[0m\u001b[1;38;2;239;35;60m9.4\u001b[0m\u001b[38;2;239;35;60m.\u001b[0m\u001b[1;38;2;239;35;60m0\u001b[0m\u001b[38;2;239;35;60m is not installed\u001b[0m\n",
       "\u001b[39m❌ \u001b[0m\u001b[38;2;239;35;60mstreamlit\u001b[0m\u001b[38;2;239;35;60m==\u001b[0m\u001b[1;38;2;239;35;60m1.27\u001b[0m\u001b[38;2;239;35;60m.\u001b[0m\u001b[1;38;2;239;35;60m0\u001b[0m\u001b[38;2;239;35;60m is not installed\u001b[0m\n",
       "\u001b[39m❌ \u001b[0m\u001b[38;2;239;35;60mstreamlit-\u001b[0m\u001b[38;2;239;35;60mchat\u001b[0m\u001b[38;2;239;35;60m==\u001b[0m\u001b[1;38;2;239;35;60m0.1\u001b[0m\u001b[38;2;239;35;60m.\u001b[0m\u001b[1;38;2;239;35;60m1\u001b[0m\u001b[38;2;239;35;60m is not installed\u001b[0m\n",
       "\u001b[39m❌ \u001b[0m\u001b[38;2;239;35;60mfaiss-cpu\u001b[0m\u001b[1;38;2;239;35;60m>\u001b[0m\u001b[38;2;239;35;60m=\u001b[0m\u001b[1;38;2;239;35;60m1.7\u001b[0m\u001b[38;2;239;35;60m,<\u001b[0m\u001b[1;38;2;239;35;60m2\u001b[0m\u001b[38;2;239;35;60m is not installed\u001b[0m\n",
       "❌ \u001b[38;2;239;35;60munstructured\u001b[0m\u001b[38;2;239;35;60m==\u001b[0m\u001b[1;38;2;239;35;60m0.10\u001b[0m\u001b[38;2;239;35;60m.\u001b[0m\u001b[1;38;2;239;35;60m16\u001b[0m\u001b[38;2;239;35;60m is not installed\u001b[0m\n",
       "❌ \u001b[38;2;239;35;60msqlalchemy\u001b[0m\u001b[38;2;239;35;60m==\u001b[0m\u001b[1;38;2;239;35;60m2.0\u001b[0m\u001b[38;2;239;35;60m.\u001b[0m\u001b[1;38;2;239;35;60m21\u001b[0m\u001b[38;2;239;35;60m is not installed\u001b[0m\n",
       "❌ \u001b[38;2;239;35;60mopensearch-\u001b[0m\u001b[38;2;239;35;60mpy\u001b[0m\u001b[38;2;239;35;60m==\u001b[0m\u001b[1;38;2;239;35;60m2.3\u001b[0m\u001b[38;2;239;35;60m.\u001b[0m\u001b[1;38;2;239;35;60m1\u001b[0m\u001b[38;2;239;35;60m is not installed\u001b[0m\n",
       "❌ \u001b[38;2;239;35;60mtiktoken is not installed\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Installing missing libraries</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mInstalling missing libraries\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pillow==9.4.0 has been installed successfully.\n",
      "streamlit==1.27.0 has been installed successfully.\n",
      "streamlit-chat==0.1.1 has been installed successfully.\n",
      "faiss-cpu>=1.7,<2 has been installed successfully.\n",
      "unstructured==0.10.16 has been installed successfully.\n",
      "sqlalchemy==2.0.21 has been installed successfully.\n",
      "opensearch-py==2.3.1 has been installed successfully.\n",
      "tiktoken has been installed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #a7c957; text-decoration-color: #a7c957\">All required libraries are installed.🎉</span>\n",
       "<span style=\"color: #a7c957; text-decoration-color: #a7c957\">You may proceed with the lab! 🚀</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;167;201;87mAll required libraries are installed.🎉\u001b[0m\n",
       "\u001b[38;2;167;201;87mYou may proceed with the lab! 🚀\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = \"../..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils.environment_validation import validate_environment, validate_model_access\n",
    "validate_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337d9778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #e85d04; text-decoration-color: #e85d04; font-weight: bold; text-decoration: underline\">MODEL ACCESS STATUS</span>\n",
       "✅ <span style=\"color: #008000; text-decoration-color: #008000\"> amazon.titan-embed-text-v1 is accessible</span>\n",
       "✅ <span style=\"color: #008000; text-decoration-color: #008000\"> anthropic.claude-</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000\">-sonnet-</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">20240229</span><span style=\"color: #008000; text-decoration-color: #008000\">-v</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1:0</span><span style=\"color: #008000; text-decoration-color: #008000\"> is accessible</span>\n",
       "✅ <span style=\"color: #008000; text-decoration-color: #008000\"> anthropic.claude-</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000\">-haiku-</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">20240307</span><span style=\"color: #008000; text-decoration-color: #008000\">-v</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1:0</span><span style=\"color: #008000; text-decoration-color: #008000\"> is accessible</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;4;38;2;232;93;4mMODEL ACCESS STATUS\u001b[0m\n",
       "✅ \u001b[32m amazon.titan-embed-text-v1 is accessible\u001b[0m\n",
       "✅ \u001b[32m anthropic.claude-\u001b[0m\u001b[1;32m3\u001b[0m\u001b[32m-sonnet-\u001b[0m\u001b[1;32m20240229\u001b[0m\u001b[32m-v\u001b[0m\u001b[1;32m1:0\u001b[0m\u001b[32m is accessible\u001b[0m\n",
       "✅ \u001b[32m anthropic.claude-\u001b[0m\u001b[1;32m3\u001b[0m\u001b[32m-haiku-\u001b[0m\u001b[1;32m20240307\u001b[0m\u001b[32m-v\u001b[0m\u001b[1;32m1:0\u001b[0m\u001b[32m is accessible\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #a7c957; text-decoration-color: #a7c957\">All required models are accessible.🎉</span>\n",
       "<span style=\"color: #a7c957; text-decoration-color: #a7c957\">You may proceed with the lab! 🚀</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;167;201;87mAll required models are accessible.🎉\u001b[0m\n",
       "\u001b[38;2;167;201;87mYou may proceed with the lab! 🚀\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "required_models = [\n",
    "    \"amazon.titan-embed-text-v1\",\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "]\n",
    "validate_model_access(required_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27610c0f-7de6-4440-8f76-decf30e3c5ca",
   "metadata": {},
   "source": [
    "---\n",
    "## Create the `boto3` client connection to Amazon Bedrock\n",
    "\n",
    "Interaction with the Bedrock API is done via the AWS SDK for Python: [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html).\n",
    "\n",
    "As you are running this notebook from [Amazon Sagemaker Studio](https://aws.amazon.com/sagemaker/studio/) and your Sagemaker Studio [execution role](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) has permissions to access Bedrock you can just run the cells below as-is in order to create a connection to Amazon Bedrock. This is also the case if you are running these notebooks from a computer whose default AWS credentials have access to Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2b2a05-78a9-40ca-9b5e-121030f9ede1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n",
      "Create new client\n",
      "  Using region: us-east-1\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from IPython.display import Markdown, display\n",
    "from rich import print as rprint\n",
    "\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "bedrock_service = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    runtime=False\n",
    ")\n",
    "\n",
    "bedrock_runtime = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    runtime=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4161e",
   "metadata": {},
   "source": [
    "Note the usage of argument `runtime=False` in the above code block. The default value of this parameter is `True`, which creates a Bedrock runtime client to perform data plane operations like invoking a model for inference. When the value of this attribute is `False`, like in this case, it creates a Bedrock client for the control plane operations, like listing the available foundation models and their versions on Bedrock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9174c4-326a-463e-92e1-8c7e47111269",
   "metadata": {},
   "source": [
    "#### Validate the connection\n",
    "\n",
    "We can check if the client works by trying out the `list_foundation_models()` method, which will list all the models available for us to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b4466-12ff-4975-9811-7a19c6206604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_service.list_foundation_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef3451d-b66a-4b11-a1ed-734bf9e7bbec",
   "metadata": {},
   "source": [
    "## Generate embeddings\n",
    "\n",
    "Embedding models convert text into vector representations that can then be utilized for a number of downstream usecases such as information retrieval, topic modelling, and classification.\n",
    "\n",
    "Bedrock currently offers a number of embedding models including Amazon Titan and Cohere Embed.\n",
    "\n",
    "Similar to the text generation model, we use the `InvokeModel` API to generate embeddings.\n",
    "\n",
    "Titan Text embedding model (`amazon.titan-embed-text-v1`) supports an input text size of up to 8192 tokens and generates and output vector of 1536 dimensions.\n",
    "It has the following input and output format:\n",
    "\n",
    "#### Titan Embed Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"inputText\": \"<text>\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Titan Embed\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"embedding\": []\n",
    "}\n",
    "```\n",
    "\n",
    "The Cohere Embed options include the English only model (`cohere.embed-english-v3`) and the multilingual model (`cohere.embed-multilingual-v3`). Both models support a max input size of 512 tokens and output a vector of 1024 dimensions.\n",
    "The payload body format is different from the Titan models and notably requires specifying the input type parameter for the given task being performed such as embedding of documents for retrieval, embedding of search queries, or embedding of text for classification. For more information, refer to the Cohere Embed documentation [here](https://docs.cohere.com/reference/embed).\n",
    "\n",
    "#### Cohere Embed Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"texts\":[\"Hello world\",\"This is a test\"],\n",
    "    \"input_type\":\"search_document | search_query | classification | clustering\" \n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645dbd8",
   "metadata": {},
   "source": [
    "Let's see how to generate embeddings of some text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1085cc56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"Amazon Bedrock supports foundation models from industry-leading providers such as \\\n",
    "AI21 Labs, Anthropic, Stability AI, and Amazon. Choose the model that is best suited to achieving \\\n",
    "your unique goals.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c54b424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The embedding vector has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1536</span> values\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.16601562</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.23632812</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.703125</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'...'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.26953125</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.609375</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.55078125</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The embedding vector has \u001b[1;36m1536\u001b[0m values\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m0.16601562\u001b[0m, \u001b[1;36m0.23632812\u001b[0m, \u001b[1;36m0.703125\u001b[0m, \u001b[32m'...'\u001b[0m, \u001b[1;36m0.26953125\u001b[0m, \u001b[1;36m-0.609375\u001b[0m, \u001b[1;36m-0.55078125\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "body = json.dumps({\"inputText\": prompt_data})\n",
    "modelId = \"amazon.titan-embed-text-v1\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "embedding = response_body.get(\"embedding\")\n",
    "rprint(f\"The embedding vector has {len(embedding)} values\\n{embedding[0:3]+['...']+embedding[-3:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da781dde-34dd-4235-954b-80261872f1fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Semantic Similarity with Amazon Titan Embeddings\n",
    "\n",
    "Semantic search refers to searching for information based on the meaning and concepts of words and phrases, rather than just matching keywords. Embedding models like Amazon Titan Embeddings allow semantic search by representing words and sentences as dense vectors that encode their semantic meaning.\n",
    "\n",
    "Semantic matching is extremely helpful for RAG because it returns results that are conceptually related to the user's query, even if they don't contain the exact keywords. This leads to more relevant and useful search results which can be injected into our LLM's prompts.\n",
    "\n",
    "First, let's take a look below to illustrate the capabilities of semantic search with Amazon Titan.\n",
    "\n",
    "The `embed_text_input` function below is an example function which will return an embedding output based on text output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b9e687-47c7-4b35-8afa-f08644db1b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embed_text_input(bedrock_client, prompt_data, modelId=\"amazon.titan-embed-text-v1\"):\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    body = json.dumps({\"inputText\": prompt_data})\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    embedding = response_body.get(\"embedding\")\n",
    "    return np.array(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78765f34-7f98-4fe2-ba1f-97844d9b98e3",
   "metadata": {},
   "source": [
    "To give an example of how this works, let's take a look at matching a user input to two \"documents\". We use a dot product calculation to rank the similarity between the input and each document, but there are many ways to do this in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e22be7b-f156-42ab-9dbd-d350864d24b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# commonly used distance metric for comparing the similarity of two vectors. It is the cosine of the angle between two vectors in a multi-dimensional space.\n",
    "def cosine_similarity(a, b):\n",
    "\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a7fbc4-d4bd-4847-a6db-8e0ae5fe4c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Things to do on vacation\" matches \"swimming, site seeing, sky diving\" with a score of 0.6\n",
      "\"Things to do on vacation\" matches \"cleaning, note taking, studying\" with a score of 0.4\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Things to do on vacation'\n",
    "document_1 = 'swimming, site seeing, sky diving'\n",
    "document_2 = 'cleaning, note taking, studying'\n",
    "\n",
    "user_input_vector = embed_text_input(bedrock_runtime, user_input)\n",
    "document_1_vector = embed_text_input(bedrock_runtime, document_1)\n",
    "document_2_vector = embed_text_input(bedrock_runtime, document_2)\n",
    "\n",
    "doc_1_match_score = cosine_similarity(user_input_vector, document_1_vector)\n",
    "doc_2_match_score = cosine_similarity(user_input_vector, document_2_vector)\n",
    "\n",
    "print(f'\"{user_input}\" matches \"{document_1}\" with a score of {doc_1_match_score:.1f}')\n",
    "print(f'\"{user_input}\" matches \"{document_2}\" with a score of {doc_2_match_score:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb5ccb0-18fa-4c30-880a-3c560a5ed249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Things to do that are productive\" matches \"swimming, site seeing, sky diving\" with a score of 0.3\n",
      "\"Things to do that are productive\" matches \"cleaning, note taking, studying\" with a score of 0.6\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Things to do that are productive'\n",
    "document_1 = 'swimming, site seeing, sky diving'\n",
    "document_2 = 'cleaning, note taking, studying'\n",
    "\n",
    "user_input_vector = embed_text_input(bedrock_runtime, user_input)\n",
    "document_1_vector = embed_text_input(bedrock_runtime, document_1)\n",
    "document_2_vector = embed_text_input(bedrock_runtime, document_2)\n",
    "\n",
    "doc_1_match_score = cosine_similarity(user_input_vector, document_1_vector)\n",
    "doc_2_match_score = cosine_similarity(user_input_vector, document_2_vector)\n",
    "\n",
    "print(f'\"{user_input}\" matches \"{document_1}\" with a score of {doc_1_match_score:.1f}')\n",
    "print(f'\"{user_input}\" matches \"{document_2}\" with a score of {doc_2_match_score:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65357b4b-7cce-4354-91fd-a9b870539cd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "The example above shows how the semantic meaning behind the user input and provided documents can be effectively ranked by Amazon Titan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48a0e8-147d-4525-a6b2-68a09af1b2c4",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "In this notebook we have successfully set up our Bedrock compatible environment and showed some basic examples of invoking Amazon Bedrock models using the AWS Python SDK. You're now ready to move on to the next notebook to start building our retrieval augmented generation (RAG) application!"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
